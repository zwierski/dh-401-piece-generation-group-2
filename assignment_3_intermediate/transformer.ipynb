{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import itertools\n",
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "data_train = pd.read_csv('../train.csv')\n",
    "data_train['beat_pitch'] = data_train['beat_pitch'].apply(ast.literal_eval)\n",
    "data_train['pitches'] = data_train['pitches'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(363, 4)"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1089, 4)"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data augmentation, move all the notes one octave up or down\n",
    "def pitch_augmentation(beat_pitch):\n",
    "    new_beat_pitch_higher = []\n",
    "    new_beat_pitch_lower = []\n",
    "    for bar in beat_pitch:\n",
    "        new_bar_higher = []\n",
    "        new_bar_lower = []\n",
    "        for (pos, pitch) in bar:\n",
    "            new_bar_higher.append((pos, pitch+12))\n",
    "            new_bar_lower.append((pos, pitch-12))\n",
    "        new_beat_pitch_higher.append(new_bar_higher)\n",
    "        new_beat_pitch_lower.append(new_bar_lower)\n",
    "    return new_beat_pitch_higher, new_beat_pitch_lower\n",
    "\n",
    "length = data_train.shape[0]\n",
    "for i in range(length):\n",
    "    beat_pitch = data_train['beat_pitch'][i]\n",
    "    new_beat_pitch_higher, new_beat_pitch_lower = pitch_augmentation(beat_pitch)\n",
    "    # append the new beat pitch to the original dataframe, leave all the other columns empty\n",
    "    data_train = data_train.append({'beat_pitch': new_beat_pitch_higher}, ignore_index=True)\n",
    "    data_train = data_train.append({'beat_pitch': new_beat_pitch_lower}, ignore_index=True)\n",
    "\n",
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>piece</th>\n",
       "      <th>beats</th>\n",
       "      <th>pitches</th>\n",
       "      <th>beat_pitch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[(1, 57), (2, 59), (3, 61), (4, 62), (5, 64),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[(1, 89), (3, 88), (5, 86), (7, 89), (9, 88),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[(1, 65), (3, 64), (5, 62), (7, 65), (9, 64),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[(1, 88), (4, 91), (5, 84), (7, 93)], [(1, 86...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[(1, 64), (4, 67), (5, 60), (7, 69)], [(1, 62...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     piece beats pitches                                         beat_pitch\n",
       "1084   NaN   NaN     NaN  [[(1, 57), (2, 59), (3, 61), (4, 62), (5, 64),...\n",
       "1085   NaN   NaN     NaN  [[(1, 89), (3, 88), (5, 86), (7, 89), (9, 88),...\n",
       "1086   NaN   NaN     NaN  [[(1, 65), (3, 64), (5, 62), (7, 65), (9, 64),...\n",
       "1087   NaN   NaN     NaN  [[(1, 88), (4, 91), (5, 84), (7, 93)], [(1, 86...\n",
       "1088   NaN   NaN     NaN  [[(1, 64), (4, 67), (5, 60), (7, 69)], [(1, 62..."
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the dictionary\n",
    "pitch_number_dict = {i:i for i in range(128)}\n",
    "pitch_number_dict['<SOS>'] = 129\n",
    "pitch_number_dict['<EOS>'] = 130\n",
    "pitch_number_dict['<UNK>'] = 131\n",
    "pitch_number_dict['<MASK>'] = 132\n",
    "pitch_number_dict['<SEP>'] = 133\n",
    "pitch_number_dict['<PAD>'] = 134\n",
    "pitch_number_dict['<BLANK>'] = 135"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the (position,pitch) to a sequence of numbers\n",
    "def change_it_to_bar_vectors(song):\n",
    "    song_1 = []\n",
    "    BLANK = pitch_number_dict['<BLANK>']\n",
    "    for bar in song:\n",
    "        vec = [BLANK] * 12\n",
    "        for tup in bar:\n",
    "            vec[tup[0]-1] = tup[1]\n",
    "        song_1.append(vec)\n",
    "    return song_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the original data to x,y\n",
    "def prepare_data(data_train,max_len):\n",
    "    # use the start, end, and middle pitch to create the pitch sequence as x\n",
    "    # use the beat_pitch to create the pitch sequence as y (use 'SEP' to separate the bars)\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "\n",
    "    # get the number of special tokens\n",
    "    SOS = pitch_number_dict['<SOS>']\n",
    "    EOS = pitch_number_dict['<EOS>']\n",
    "    SEP = pitch_number_dict['<SEP>']\n",
    "    PAD = pitch_number_dict['<PAD>']\n",
    "    BLANK = pitch_number_dict['<BLANK>']\n",
    "\n",
    "    for i in range(len(data_train)):\n",
    "        piece = data_train.loc[i,'beat_pitch']\n",
    "        piece = change_it_to_bar_vectors(piece)\n",
    "        # add <SOS>\n",
    "        piece_x = [SOS]\n",
    "        piece_y = [SOS]\n",
    "        for bar in piece:\n",
    "            # filter the 0 in the bar\n",
    "            filtered_bar = [pitch for pitch in bar if pitch != 0]\n",
    "            try:\n",
    "                piece_x.extend([filtered_bar[0]] + [BLANK]*6 + [int(np.median(filtered_bar))]  + [filtered_bar[-1]] + [BLANK]*3 + [SEP])\n",
    "            except:\n",
    "                pass\n",
    "            piece_y.extend(bar + [SEP])\n",
    "        # remove the last <SEP>\n",
    "        piece_x = piece_x[:-1]\n",
    "        piece_y = piece_y[:-1]\n",
    "\n",
    "        # add <PAD>\n",
    "        piece_x.extend([PAD] * (max_len - len(piece_x) -1))\n",
    "        piece_y.extend([PAD] * (max_len - len(piece_y)))\n",
    "        \n",
    "        # add <EOS>\n",
    "        piece_x.append(EOS)\n",
    "        piece_y.append(EOS)\n",
    "\n",
    "        x_train.append(piece_x)\n",
    "        y_train.append(piece_y)\n",
    "    return x_train,y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train = prepare_data(data_train,max_len=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = torch.tensor(self.x[index])\n",
    "        y = torch.tensor(self.y[index])\n",
    "        return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(Dataset(x_train,y_train),\n",
    "                                     batch_size=8,\n",
    "                                     shuffle=True,\n",
    "                                     collate_fn=None,\n",
    "                                     drop_last=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(Q, K, V, mask):\n",
    "    # Q, K, V: (batch_size, len_of_sequence, head_number=4, embedding_size_per_head=8)\n",
    "    # Q, K, V: (len_of_training_set, head_number=4, len_of_sequence, embedding_size_per_head=8)\n",
    "    # Q*K: get the attention score between each word in the sequence\n",
    "    # Q*K: (len_of_training_set, head_number=4, len_of_sequence, len_of_sequence)\n",
    "    score = torch.matmul(Q,K.permute(0,1,3,2)) / np.sqrt(8)\n",
    "    \n",
    "    # mask the score\n",
    "    # mask: (len_of_training_set, 1, len_of_sequence, len_of_sequence)\n",
    "    score = score.masked_fill(mask, -float('inf'))\n",
    "    \n",
    "    # softmax the score\n",
    "    score = torch.softmax(score, dim=-1)\n",
    "\n",
    "    # score*V: get the weighted sum of the value\n",
    "    # score*V: (len_of_training_set, head_number=4, len_of_sequence, embedding_size_per_head=8)\n",
    "    score = torch.matmul(score, V)\n",
    "\n",
    "    # concat the heads\n",
    "    # [batch_size, head_number=4, len_of_sequence, embedding_size_per_head=8] -> [batch_size, len_of_sequence, embedding_size=4*8=32]\n",
    "    score = score.permute(0,2,1,3).reshape(score.shape[0], score.shape[2], -1)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHead(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.head_number = 4\n",
    "        self.embedding_size_per_head = 8\n",
    "\n",
    "        self.fc_Q = torch.nn.Linear(32,32)\n",
    "        self.fc_K = torch.nn.Linear(32,32)\n",
    "        self.fc_V = torch.nn.Linear(32,32)\n",
    "\n",
    "        self.fc_out = torch.nn.Linear(32,32)\n",
    "\n",
    "        self.norm = torch.nn.LayerNorm(normalized_shape=32, elementwise_affine=True)\n",
    "        self.dropout = torch.nn.Dropout(0.1)\n",
    "    \n",
    "    def forward(self, Q, K, V, mask):\n",
    "        # Q, K, V: (batch_size, len_of_sequence, embedding_size=32)\n",
    "        batch_size = Q.shape[0]\n",
    "        len_of_sequence = Q.shape[1]\n",
    "\n",
    "        # keep the original Q\n",
    "        Q_original = Q\n",
    "\n",
    "        # normalize\n",
    "        Q = self.norm(Q)\n",
    "        K = self.norm(K)\n",
    "        V = self.norm(V)\n",
    "        \n",
    "        # linear projection, the dimension will not change\n",
    "        Q = self.fc_Q(Q)\n",
    "        K = self.fc_K(K)\n",
    "        V = self.fc_V(V)\n",
    "        \n",
    "        # split the heads   \n",
    "        # Q, K, V: (batch_size, len_of_sequence, head_number=4, embedding_size_per_head=8)\n",
    "        Q = Q.reshape(batch_size, len_of_sequence, self.head_number, self.embedding_size_per_head).permute(0,2,1,3)\n",
    "        K = K.reshape(batch_size, len_of_sequence, self.head_number, self.embedding_size_per_head).permute(0,2,1,3)\n",
    "        V = V.reshape(batch_size, len_of_sequence, self.head_number, self.embedding_size_per_head).permute(0,2,1,3)\n",
    "\n",
    "        # get the attention score\n",
    "        # score: (batch_size, len_of_sequence, embedding_size=4*8=32)\n",
    "        score = attention(Q, K, V, mask)\n",
    "        \n",
    "        # get the output\n",
    "        # score: (batch_size, len_of_sequence, embedding_size=32)\n",
    "        score = self.dropout(self.fc_out(score))\n",
    "\n",
    "        # residual connection\n",
    "        score = score + Q_original\n",
    "\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionEmbedding(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # pos:index of the position, i: index of the embedding, d_model: embedding size\n",
    "        def get_pe(pos, i, d_model):\n",
    "            denominator = 1e4 ** (i / d_model)\n",
    "            pe = pos / denominator\n",
    "\n",
    "            if i % 2 == 0:\n",
    "                return math.sin(pe)\n",
    "            return math.cos(pe)\n",
    "        \n",
    "        # initialize the position embedding\n",
    "        pe = torch.empty(400,32)\n",
    "        for i in range(400):\n",
    "            for j in range(32):\n",
    "                pe[i,j] = get_pe(i,j,32)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "        # word embedding\n",
    "        self.embed = torch.nn.Embedding(136,32)\n",
    "        # initialize the word embedding\n",
    "        self.embed.weight.data.normal_(0, 0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [8, 400] -> [8, 400, 32]\n",
    "        embed = self.embed(x)\n",
    "        \n",
    "        # add the position embedding\n",
    "        # embed: [8, 400, 32] + [1, 400, 32] -> [8, 400, 32]\n",
    "        embed = embed + self.pe\n",
    "        return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnectedOutput(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features=32, out_features=64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(in_features=64, out_features=32),\n",
    "            torch.nn.Dropout(0.1)\n",
    "        )\n",
    "        self.norm = torch.nn.LayerNorm(normalized_shape=32)\n",
    "    def forward(self, x):\n",
    "        # get the original x\n",
    "        x_original = x.clone()\n",
    "        # normalize\n",
    "        x = self.norm(x)\n",
    "        # linear projection\n",
    "        x = self.fc(x)\n",
    "        # residual connection\n",
    "        x = x + x_original\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_pad(data):\n",
    "    # data: (len_of_training_set, len_of_sequence)\n",
    "    mask = (data == pitch_number_dict['<PAD>'])\n",
    "\n",
    "    # mask: (len_of_training_set, 1, 1, len_of_sequence)\n",
    "    mask = mask.reshape(-1,1,1,mask.shape[1])\n",
    "    # mask: (len_of_training_set, 1, len_of_sequence, len_of_sequence)\n",
    "    mask = mask.expand(-1,1,mask.shape[3],mask.shape[3])\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_tril(data):\n",
    "    # data: (len_of_training_set, len_of_sequence)\n",
    "    tril = 1 - torch.tril(torch.ones(1,data.shape[1],data.shape[1]))\n",
    "    mask = (data == pitch_number_dict['<PAD>'])\n",
    "    mask = mask.unsqueeze(1).long()\n",
    "    mask = mask + tril\n",
    "    mask = mask > 0\n",
    "    mask = (mask == 1).unsqueeze(dim=1)\n",
    "    return mask"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.multihead = MultiHead()\n",
    "        self.fc = FullyConnectedOutput()\n",
    "    \n",
    "    def forward(self, x, mask):\n",
    "        # x: (len_of_training_set, len_of_sequence, embedding_size=32)\n",
    "        # mask: (len_of_training_set, 1, len_of_sequence, len_of_sequence)\n",
    "        score = self.multihead(x, x, x, mask)\n",
    "        out = self.fc(score)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer_1 = EncoderLayer()\n",
    "        self.layer_2 = EncoderLayer()\n",
    "        self.layer_3 = EncoderLayer()\n",
    "    \n",
    "    def forward(self, x, mask):\n",
    "        x = self.layer_1(x, mask)\n",
    "        x = self.layer_2(x, mask)\n",
    "        x = self.layer_3(x, mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.multihead_1 = MultiHead()\n",
    "        self.multihead_2 = MultiHead()\n",
    "        self.fc = FullyConnectedOutput()\n",
    "    \n",
    "    def forward(self,x,y,mask_pad_x,mask_tril_y):\n",
    "        # x: (len_of_training_set, len_of_sequence, embedding_size=32)\n",
    "        # y: (len_of_training_set, len_of_sequence, embedding_size=32)\n",
    "        # mask_pad_x: (len_of_training_set, 1, len_of_sequence, len_of_sequence)\n",
    "        # mask_tril_y: (len_of_training_set, 1, len_of_sequence, len_of_sequence)\n",
    "        y = self.multihead_1(y, y, y, mask_tril_y)\n",
    "        y = self.multihead_2(y, x, x, mask_pad_x)\n",
    "        out = self.fc(y)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer_1 = DecoderLayer()\n",
    "        self.layer_2 = DecoderLayer()\n",
    "        self.layer_3 = DecoderLayer()\n",
    "    \n",
    "    def forward(self,x,y,mask_pad_x,mask_tril_y):\n",
    "        y = self.layer_1(x,y,mask_pad_x,mask_tril_y)\n",
    "        y = self.layer_2(x,y,mask_pad_x,mask_tril_y)\n",
    "        y = self.layer_3(x,y,mask_pad_x,mask_tril_y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embed = PositionEmbedding()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "        self.fc_out = torch.nn.Linear(32,136)\n",
    "    \n",
    "    def forward(self,x,y):\n",
    "        mask_pad_x = mask_pad(x)\n",
    "        mask_tril_y = mask_tril(y)\n",
    "        # x: (len_of_training_set, len_of_sequence) -> (len_of_training_set, len_of_sequence, embedding_size=32)\n",
    "        # y: (len_of_training_set, len_of_sequence) -> (len_of_training_set, len_of_sequence, embedding_size=32)\n",
    "        x,y = self.embed(x),self.embed(y)\n",
    "\n",
    "        # encoder layer\n",
    "        # x: (len_of_training_set, len_of_sequence, embedding_size=32) -> (len_of_training_set, len_of_sequence, embedding_size=32)\n",
    "        x = self.encoder(x, mask_pad_x)\n",
    "\n",
    "        # decoder layer\n",
    "        # y: (len_of_training_set, len_of_sequence, embedding_size=32) -> (len_of_training_set, len_of_sequence, embedding_size=32)\n",
    "        y = self.decoder(x, y, mask_pad_x, mask_tril_y)\n",
    "\n",
    "        # fully connected layer\n",
    "        # y: (len_of_training_set, len_of_sequence, embedding_size=32) -> (len_of_training_set, len_of_sequence, embedding_size=136)\n",
    "        y = self.fc_out(y)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer()\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=2e-3)\n",
    "sched = torch.optim.lr_scheduler.StepLR(optim, step_size=3, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "best accuracy:  0.4885654885654886  best accuracy loss:  2.482811450958252\n",
      "epoch:  1\n",
      "best accuracy:  0.4885654885654886  best accuracy loss:  2.482811450958252\n",
      "epoch:  2\n",
      "best accuracy:  0.5571531272465852  best accuracy loss:  1.6150192022323608\n",
      "epoch:  3\n",
      "best accuracy:  0.5571531272465852  best accuracy loss:  1.6150192022323608\n",
      "epoch:  4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-370-2937d26d8881>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;31m# x: [8,400], y: [8,401]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m136\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-367-c6d21b966917>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;31m# decoder layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;31m# y: (len_of_training_set, len_of_sequence, embedding_size=32) -> (len_of_training_set, len_of_sequence, embedding_size=32)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask_pad_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask_tril_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m# fully connected layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-366-ce00e5aa539d>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, y, mask_pad_x, mask_tril_y)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmask_pad_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmask_tril_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmask_pad_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmask_tril_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmask_pad_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmask_tril_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-365-56d0992d0561>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, y, mask_pad_x, mask_tril_y)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m# mask_tril_y: (len_of_training_set, 1, len_of_sequence, len_of_sequence)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultihead_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask_tril_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultihead_2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask_pad_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-358-ad32f9014fb0>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, Q, K, V, mask)\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;31m# get the attention score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;31m# score: (batch_size, len_of_sequence, embedding_size=4*8=32)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mV\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;31m# get the output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-357-ad22bda32be1>\u001b[0m in \u001b[0;36mattention\u001b[1;34m(Q, K, V, mask)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# mask the score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# mask: (len_of_training_set, 1, len_of_sequence, len_of_sequence)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmasked_fill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'inf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# softmax the score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_acc = 0\n",
    "best_acc_loss = 0\n",
    "\n",
    "# load the pretrained model\n",
    "# model.load_state_dict(torch.load('transformer.pth'))\n",
    "\n",
    "for epoch in range(30):\n",
    "    print('epoch: ',epoch)\n",
    "    for i,(x,y) in enumerate(loader):\n",
    "        # x: [8,400], y: [8,401]\n",
    "        pred = model(x,y[:, :-1])\n",
    "        pred = pred.reshape(-1,136)\n",
    "        y = y[:,1:].reshape(-1)\n",
    "\n",
    "        select = (y != pitch_number_dict['<PAD>'])\n",
    "        pred = pred[select]\n",
    "        y = y[select]\n",
    "\n",
    "        loss = loss_func(pred,y)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            pred = pred.argmax(dim=1)\n",
    "            correct = (pred == y).sum().item()\n",
    "            acc = correct / len(pred)\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_acc_loss = loss.item()\n",
    "                torch.save(model.state_dict(), 'transformer.pth')\n",
    "    print('best accuracy: ',best_acc, ' best accuracy loss: ',best_acc_loss)\n",
    "    sched.step()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    x = torch.tensor(x).unsqueeze(0)\n",
    "    print(x)\n",
    "    # x: [1,400]\n",
    "    model.eval()\n",
    "    \n",
    "    # initialize the mask\n",
    "    mask_pad_x = mask_pad(x)\n",
    "\n",
    "    # initialize the output\n",
    "    target = [pitch_number_dict['<SOS>']] + [pitch_number_dict['<PAD>']] * 399\n",
    "    target = torch.tensor(target).unsqueeze(0)\n",
    "\n",
    "    # embed the input, [1, 400] -> [1, 400, 32]\n",
    "    x = model.embed(x)\n",
    "\n",
    "    # encoder layer\n",
    "    # x: [1, 400, 32] -> [1, 400, 32]\n",
    "    x = model.encoder(x, mask_pad_x)\n",
    "\n",
    "    # generate the output\n",
    "    for i in range(399):\n",
    "        y = target\n",
    "\n",
    "        # initialize the mask\n",
    "        mask_tril_y = mask_tril(y)\n",
    "\n",
    "        # embed the output, [1, 400] -> [1, 400, 32]\n",
    "        y = model.embed(y)\n",
    "\n",
    "        # decoder layer\n",
    "        # y: [1, 400, 32] -> [1, 400, 32]\n",
    "        y = model.decoder(x, y, mask_pad_x, mask_tril_y)\n",
    "\n",
    "        # fully connected layer\n",
    "        # y: [1, 400, 32] -> [1, 400, 136]\n",
    "        out = model.fc_out(y)\n",
    "\n",
    "        # get the output for the current position\n",
    "        # out: [1, 400, 136] -> [1, 136]\n",
    "        out = out[:,i,:]\n",
    "\n",
    "        # get the index of the maximum value\n",
    "        # out: [1, 136] -> [1]\n",
    "        out = out.argmax(dim=1).detach()\n",
    "\n",
    "        # update the target\n",
    "        target[:,i+1] = out\n",
    "\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_x(triple_counter):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089\n",
      "tensor([[[129,  74,  67,  ..., 134, 134, 130],\n",
      "         [129,  67,  78,  ..., 134, 134, 130],\n",
      "         [129,  81,  77,  ..., 134, 134, 130],\n",
      "         ...,\n",
      "         [129,  65,  64,  ..., 134, 134, 130],\n",
      "         [129,  88,  89,  ..., 134, 134, 130],\n",
      "         [129,  64,  65,  ..., 134, 134, 130]]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 1089, 4, 8]' is invalid for input of size 13939200",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-334-0ae2c59647db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtest_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-331-890d059a6586>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m# encoder layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m# x: [1, 400, 32] -> [1, 400, 32]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask_pad_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m# generate the output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-311-5be39bdde774>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, mask)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-310-cb69ffef9e7d>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, mask)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;31m# x: (len_of_training_set, len_of_sequence, embedding_size=32)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;31m# mask: (len_of_training_set, 1, len_of_sequence, len_of_sequence)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultihead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-305-ad32f9014fb0>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, Q, K, V, mask)\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;31m# split the heads\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;31m# Q, K, V: (batch_size, len_of_sequence, head_number=4, embedding_size_per_head=8)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mQ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mQ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen_of_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead_number\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_size_per_head\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[0mK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen_of_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead_number\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_size_per_head\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mV\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen_of_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead_number\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_size_per_head\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[1, 1089, 4, 8]' is invalid for input of size 13939200"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    # x = generate_x(triple_counter)\n",
    "    # pred = predict(x)\n",
    "    test_x = x_train[i]\n",
    "    print(len(test_x))\n",
    "    pred = predict(test_x)\n",
    "    print(pred)\n",
    "    print(y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
