{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import itertools\n",
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "data_train = pd.read_csv('../train.csv')\n",
    "data_train['beat_pitch'] = data_train['beat_pitch'].apply(ast.literal_eval)\n",
    "data_train['pitches'] = data_train['pitches'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(363, 4)"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1089, 4)"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data augmentation, move all the notes one octave up or down\n",
    "def pitch_augmentation(beat_pitch):\n",
    "    new_beat_pitch_higher = []\n",
    "    new_beat_pitch_lower = []\n",
    "    for bar in beat_pitch:\n",
    "        new_bar_higher = []\n",
    "        new_bar_lower = []\n",
    "        for (pos, pitch) in bar:\n",
    "            new_bar_higher.append((pos, pitch+12))\n",
    "            new_bar_lower.append((pos, pitch-12))\n",
    "        new_beat_pitch_higher.append(new_bar_higher)\n",
    "        new_beat_pitch_lower.append(new_bar_lower)\n",
    "    return new_beat_pitch_higher, new_beat_pitch_lower\n",
    "\n",
    "length = data_train.shape[0]\n",
    "for i in range(length):\n",
    "    beat_pitch = data_train['beat_pitch'][i]\n",
    "    new_beat_pitch_higher, new_beat_pitch_lower = pitch_augmentation(beat_pitch)\n",
    "    # append the new beat pitch to the original dataframe, leave all the other columns empty\n",
    "    data_train = data_train.append({'beat_pitch': new_beat_pitch_higher}, ignore_index=True)\n",
    "    data_train = data_train.append({'beat_pitch': new_beat_pitch_lower}, ignore_index=True)\n",
    "\n",
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>piece</th>\n",
       "      <th>beats</th>\n",
       "      <th>pitches</th>\n",
       "      <th>beat_pitch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[(1, 57), (2, 59), (3, 61), (4, 62), (5, 64),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[(1, 89), (3, 88), (5, 86), (7, 89), (9, 88),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[(1, 65), (3, 64), (5, 62), (7, 65), (9, 64),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[(1, 88), (4, 91), (5, 84), (7, 93)], [(1, 86...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[(1, 64), (4, 67), (5, 60), (7, 69)], [(1, 62...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     piece beats pitches                                         beat_pitch\n",
       "1084   NaN   NaN     NaN  [[(1, 57), (2, 59), (3, 61), (4, 62), (5, 64),...\n",
       "1085   NaN   NaN     NaN  [[(1, 89), (3, 88), (5, 86), (7, 89), (9, 88),...\n",
       "1086   NaN   NaN     NaN  [[(1, 65), (3, 64), (5, 62), (7, 65), (9, 64),...\n",
       "1087   NaN   NaN     NaN  [[(1, 88), (4, 91), (5, 84), (7, 93)], [(1, 86...\n",
       "1088   NaN   NaN     NaN  [[(1, 64), (4, 67), (5, 60), (7, 69)], [(1, 62..."
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the dictionary\n",
    "pitch_number_dict = {i:i for i in range(128)}\n",
    "pitch_number_dict['<SOS>'] = 129\n",
    "pitch_number_dict['<EOS>'] = 130\n",
    "pitch_number_dict['<UNK>'] = 131\n",
    "pitch_number_dict['<MASK>'] = 132\n",
    "pitch_number_dict['<SEP>'] = 133\n",
    "pitch_number_dict['<PAD>'] = 134\n",
    "pitch_number_dict['<BLANK>'] = 135"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the (position,pitch) to a sequence of numbers\n",
    "def change_it_to_bar_vectors(song):\n",
    "    song_1 = []\n",
    "    BLANK = pitch_number_dict['<BLANK>']\n",
    "    for bar in song:\n",
    "        vec = [BLANK] * 12\n",
    "        for tup in bar:\n",
    "            vec[tup[0]-1] = tup[1]\n",
    "        song_1.append(vec)\n",
    "    return song_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the original data to x,y\n",
    "def prepare_data(data_train,max_len):\n",
    "    # use the start, end, and middle pitch to create the pitch sequence as x\n",
    "    # use the beat_pitch to create the pitch sequence as y (use 'SEP' to separate the bars)\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "\n",
    "    # get the number of special tokens\n",
    "    SOS = pitch_number_dict['<SOS>']\n",
    "    EOS = pitch_number_dict['<EOS>']\n",
    "    SEP = pitch_number_dict['<SEP>']\n",
    "    PAD = pitch_number_dict['<PAD>']\n",
    "\n",
    "    for i in range(len(data_train)):\n",
    "        piece = data_train.loc[i,'beat_pitch']\n",
    "        piece = change_it_to_bar_vectors(piece)\n",
    "        piece_x = []\n",
    "        piece_y = []\n",
    "\n",
    "        for bar in piece:\n",
    "            piece_x.extend(bar + [SEP])\n",
    "            piece_y.extend(bar + [SEP])\n",
    "        \n",
    "        # remove the last <SEP>\n",
    "        piece_x = piece_x[:-1]\n",
    "        piece_y = piece_y[1:]\n",
    "\n",
    "        # add <SOS>\n",
    "        piece_x = [SOS] + piece_x\n",
    "        piece_y = [SOS] + piece_y\n",
    "\n",
    "        # add <PAD>\n",
    "        piece_x.extend([PAD] * (max_len - len(piece_x)))\n",
    "        piece_y.extend([PAD] * (max_len - len(piece_y)))\n",
    "        \n",
    "        # add <EOS>\n",
    "        piece_x.append(EOS)\n",
    "        piece_y.append(EOS)\n",
    "\n",
    "        x_train.append(piece_x)\n",
    "        y_train.append(piece_y)\n",
    "    return x_train,y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train = prepare_data(data_train,max_len=399)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 400\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train[0]),len(y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = torch.tensor(self.x[index])\n",
    "        y = torch.tensor(self.y[index])\n",
    "        return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(Dataset(x_train,y_train),\n",
    "                                     batch_size=8,\n",
    "                                     shuffle=True,\n",
    "                                     collate_fn=None,\n",
    "                                     drop_last=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(Q, K, V, mask):\n",
    "    # Q, K, V: (batch_size, len_of_sequence, head_number=4, embedding_size_per_head=8)\n",
    "    # Q, K, V: (len_of_training_set, head_number=4, len_of_sequence, embedding_size_per_head=8)\n",
    "    # Q*K: get the attention score between each word in the sequence\n",
    "    # Q*K: (len_of_training_set, head_number=4, len_of_sequence, len_of_sequence)\n",
    "    score = torch.matmul(Q,K.permute(0,1,3,2)) / np.sqrt(8)\n",
    "    \n",
    "    # mask the score\n",
    "    # mask: (len_of_training_set, 1, len_of_sequence, len_of_sequence)\n",
    "    score = score.masked_fill(mask, -float('inf'))\n",
    "    \n",
    "    # softmax the score\n",
    "    score = torch.softmax(score, dim=-1)\n",
    "\n",
    "    # score*V: get the weighted sum of the value\n",
    "    # score*V: (len_of_training_set, head_number=4, len_of_sequence, embedding_size_per_head=8)\n",
    "    score = torch.matmul(score, V)\n",
    "\n",
    "    # concat the heads\n",
    "    # [batch_size, head_number=4, len_of_sequence, embedding_size_per_head=8] -> [batch_size, len_of_sequence, embedding_size=4*8=32]\n",
    "    score = score.permute(0,2,1,3).reshape(score.shape[0], score.shape[2], -1)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHead(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.head_number = 4\n",
    "        self.embedding_size_per_head = 8\n",
    "\n",
    "        self.fc_Q = torch.nn.Linear(32,32)\n",
    "        self.fc_K = torch.nn.Linear(32,32)\n",
    "        self.fc_V = torch.nn.Linear(32,32)\n",
    "\n",
    "        self.fc_out = torch.nn.Linear(32,32)\n",
    "\n",
    "        self.norm = torch.nn.LayerNorm(normalized_shape=32, elementwise_affine=True)\n",
    "        self.dropout = torch.nn.Dropout(0.1)\n",
    "    \n",
    "    def forward(self, Q, K, V, mask):\n",
    "        # Q, K, V: (batch_size, len_of_sequence, embedding_size=32)\n",
    "        batch_size = Q.shape[0]\n",
    "        len_of_sequence = Q.shape[1]\n",
    "\n",
    "        # keep the original Q\n",
    "        Q_original = Q\n",
    "\n",
    "        # normalize\n",
    "        Q = self.norm(Q)\n",
    "        K = self.norm(K)\n",
    "        V = self.norm(V)\n",
    "        \n",
    "        # linear projection, the dimension will not change\n",
    "        Q = self.fc_Q(Q)\n",
    "        K = self.fc_K(K)\n",
    "        V = self.fc_V(V)\n",
    "        \n",
    "        # split the heads   \n",
    "        # Q, K, V: (batch_size, len_of_sequence, head_number=4, embedding_size_per_head=8)\n",
    "        Q = Q.reshape(batch_size, len_of_sequence, self.head_number, self.embedding_size_per_head).permute(0,2,1,3)\n",
    "        K = K.reshape(batch_size, len_of_sequence, self.head_number, self.embedding_size_per_head).permute(0,2,1,3)\n",
    "        V = V.reshape(batch_size, len_of_sequence, self.head_number, self.embedding_size_per_head).permute(0,2,1,3)\n",
    "\n",
    "        # get the attention score\n",
    "        # score: (batch_size, len_of_sequence, embedding_size=4*8=32)\n",
    "        score = attention(Q, K, V, mask)\n",
    "        \n",
    "        # get the output\n",
    "        # score: (batch_size, len_of_sequence, embedding_size=32)\n",
    "        score = self.dropout(self.fc_out(score))\n",
    "\n",
    "        # residual connection\n",
    "        score = score + Q_original\n",
    "\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionEmbedding(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # pos:index of the position, i: index of the embedding, d_model: embedding size\n",
    "        def get_pe(pos, i, d_model):\n",
    "            denominator = 1e4 ** (i / d_model)\n",
    "            pe = pos / denominator\n",
    "\n",
    "            if i % 2 == 0:\n",
    "                return math.sin(pe)\n",
    "            return math.cos(pe)\n",
    "        \n",
    "        # initialize the position embedding\n",
    "        pe = torch.empty(400,32)\n",
    "        for i in range(400):\n",
    "            for j in range(32):\n",
    "                pe[i,j] = get_pe(i,j,32)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "        # word embedding\n",
    "        self.embed = torch.nn.Embedding(136,32)\n",
    "        # initialize the word embedding\n",
    "        self.embed.weight.data.normal_(0, 0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [8, 400] -> [8, 400, 32]\n",
    "        embed = self.embed(x)\n",
    "        \n",
    "        # add the position embedding\n",
    "        # embed: [8, 400, 32] + [1, 400, 32] -> [8, 400, 32]\n",
    "        embed = embed + self.pe\n",
    "        return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnectedOutput(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features=32, out_features=64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(in_features=64, out_features=32),\n",
    "            torch.nn.Dropout(0.1)\n",
    "        )\n",
    "        self.norm = torch.nn.LayerNorm(normalized_shape=32)\n",
    "    def forward(self, x):\n",
    "        # get the original x\n",
    "        x_original = x.clone()\n",
    "        # normalize\n",
    "        x = self.norm(x)\n",
    "        # linear projection\n",
    "        x = self.fc(x)\n",
    "        # residual connection\n",
    "        x = x + x_original\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_pad(data):\n",
    "    # data: (len_of_training_set, len_of_sequence)\n",
    "    mask = (data == pitch_number_dict['<PAD>'])\n",
    "\n",
    "    # mask: (len_of_training_set, 1, 1, len_of_sequence)\n",
    "    mask = mask.reshape(-1,1,1,mask.shape[1])\n",
    "    # mask: (len_of_training_set, 1, len_of_sequence, len_of_sequence)\n",
    "    mask = mask.expand(-1,1,mask.shape[3],mask.shape[3])\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_tril(data):\n",
    "    # data: (len_of_training_set, len_of_sequence)\n",
    "    tril = 1 - torch.tril(torch.ones(1,data.shape[1],data.shape[1]))\n",
    "    mask = (data == pitch_number_dict['<PAD>'])\n",
    "    mask = mask.unsqueeze(1).long()\n",
    "    mask = mask + tril\n",
    "    mask = mask > 0\n",
    "    mask = (mask == 1).unsqueeze(dim=1)\n",
    "    return mask"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.multihead = MultiHead()\n",
    "        self.fc = FullyConnectedOutput()\n",
    "    \n",
    "    def forward(self, x, mask):\n",
    "        # x: (len_of_training_set, len_of_sequence, embedding_size=32)\n",
    "        # mask: (len_of_training_set, 1, len_of_sequence, len_of_sequence)\n",
    "        score = self.multihead(x, x, x, mask)\n",
    "        out = self.fc(score)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer_1 = EncoderLayer()\n",
    "        self.layer_2 = EncoderLayer()\n",
    "        self.layer_3 = EncoderLayer()\n",
    "    \n",
    "    def forward(self, x, mask):\n",
    "        x = self.layer_1(x, mask)\n",
    "        x = self.layer_2(x, mask)\n",
    "        x = self.layer_3(x, mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.multihead_1 = MultiHead()\n",
    "        self.multihead_2 = MultiHead()\n",
    "        self.fc = FullyConnectedOutput()\n",
    "    \n",
    "    def forward(self,x,y,mask_pad_x,mask_tril_y):\n",
    "        # x: (len_of_training_set, len_of_sequence, embedding_size=32)\n",
    "        # y: (len_of_training_set, len_of_sequence, embedding_size=32)\n",
    "        # mask_pad_x: (len_of_training_set, 1, len_of_sequence, len_of_sequence)\n",
    "        # mask_tril_y: (len_of_training_set, 1, len_of_sequence, len_of_sequence)\n",
    "        y = self.multihead_1(y, y, y, mask_tril_y)\n",
    "        y = self.multihead_2(y, x, x, mask_pad_x)\n",
    "        out = self.fc(y)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer_1 = DecoderLayer()\n",
    "        self.layer_2 = DecoderLayer()\n",
    "        self.layer_3 = DecoderLayer()\n",
    "    \n",
    "    def forward(self,x,y,mask_pad_x,mask_tril_y):\n",
    "        y = self.layer_1(x,y,mask_pad_x,mask_tril_y)\n",
    "        y = self.layer_2(x,y,mask_pad_x,mask_tril_y)\n",
    "        y = self.layer_3(x,y,mask_pad_x,mask_tril_y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embed = PositionEmbedding()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "        self.fc_out = torch.nn.Linear(32,136)\n",
    "    \n",
    "    def forward(self,x,y):\n",
    "        mask_pad_x = mask_pad(x)\n",
    "        mask_tril_y = mask_tril(y)\n",
    "        # x: (len_of_training_set, len_of_sequence) -> (len_of_training_set, len_of_sequence, embedding_size=32)\n",
    "        # y: (len_of_training_set, len_of_sequence) -> (len_of_training_set, len_of_sequence, embedding_size=32)\n",
    "        x,y = self.embed(x),self.embed(y)\n",
    "\n",
    "        # encoder layer\n",
    "        # x: (len_of_training_set, len_of_sequence, embedding_size=32) -> (len_of_training_set, len_of_sequence, embedding_size=32)\n",
    "        x = self.encoder(x, mask_pad_x)\n",
    "\n",
    "        # decoder layer\n",
    "        # y: (len_of_training_set, len_of_sequence, embedding_size=32) -> (len_of_training_set, len_of_sequence, embedding_size=32)\n",
    "        y = self.decoder(x, y, mask_pad_x, mask_tril_y)\n",
    "\n",
    "        # fully connected layer\n",
    "        # y: (len_of_training_set, len_of_sequence, embedding_size=32) -> (len_of_training_set, len_of_sequence, embedding_size=136)\n",
    "        y = self.fc_out(y)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer()\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=2e-3)\n",
    "sched = torch.optim.lr_scheduler.StepLR(optim, step_size=3, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "best accuracy:  1.0  best accuracy loss:  0.001516359276138246\n",
      "epoch:  1\n",
      "best accuracy:  1.0  best accuracy loss:  0.001516359276138246\n",
      "epoch:  2\n",
      "best accuracy:  1.0  best accuracy loss:  0.001516359276138246\n",
      "epoch:  3\n",
      "best accuracy:  1.0  best accuracy loss:  0.001516359276138246\n",
      "epoch:  4\n",
      "best accuracy:  1.0  best accuracy loss:  0.001516359276138246\n",
      "epoch:  5\n",
      "best accuracy:  1.0  best accuracy loss:  0.001516359276138246\n",
      "epoch:  6\n",
      "best accuracy:  1.0  best accuracy loss:  0.001516359276138246\n",
      "epoch:  7\n",
      "best accuracy:  1.0  best accuracy loss:  0.001516359276138246\n",
      "epoch:  8\n",
      "best accuracy:  1.0  best accuracy loss:  0.001516359276138246\n",
      "epoch:  9\n",
      "best accuracy:  1.0  best accuracy loss:  0.001516359276138246\n",
      "epoch:  10\n",
      "best accuracy:  1.0  best accuracy loss:  0.001516359276138246\n",
      "epoch:  11\n",
      "best accuracy:  1.0  best accuracy loss:  0.001516359276138246\n",
      "epoch:  12\n",
      "best accuracy:  1.0  best accuracy loss:  0.001516359276138246\n",
      "epoch:  13\n",
      "best accuracy:  1.0  best accuracy loss:  0.001516359276138246\n",
      "epoch:  14\n",
      "best accuracy:  1.0  best accuracy loss:  0.001516359276138246\n",
      "epoch:  15\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-465-c0e2ff6c5cd2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m             )\n\u001b[1;32m--> 487\u001b[1;33m         torch.autograd.backward(\n\u001b[0m\u001b[0;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m         )\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_acc = 0\n",
    "best_acc_loss = 0\n",
    "\n",
    "# load the pretrained model\n",
    "# model.load_state_dict(torch.load('transformer.pth'))\n",
    "\n",
    "for epoch in range(30):\n",
    "    print('epoch: ',epoch)\n",
    "    for i,(x,y) in enumerate(loader):\n",
    "        # x: [8,400], y: [8,400]\n",
    "        pred = model(x,y)\n",
    "        pred = pred.reshape(-1,136)\n",
    "        y = y.reshape(-1)\n",
    "\n",
    "        select = (y != pitch_number_dict['<PAD>'])\n",
    "        pred = pred[select]\n",
    "        y = y[select]\n",
    "\n",
    "        loss = loss_func(pred,y)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            pred = pred.argmax(dim=1)\n",
    "            correct = (pred == y).sum().item()\n",
    "            acc = correct / len(pred)\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_acc_loss = loss.item()\n",
    "                torch.save(model.state_dict(), 'transformer.pth')\n",
    "    print('best accuracy: ',best_acc, ' best accuracy loss: ',best_acc_loss)\n",
    "    sched.step()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    x = torch.tensor(x).unsqueeze(0)\n",
    "    print(x)\n",
    "    # x: [1,400]\n",
    "    model.eval()\n",
    "    \n",
    "    # initialize the mask\n",
    "    mask_pad_x = mask_pad(x)\n",
    "\n",
    "    # initialize the output\n",
    "    target = [pitch_number_dict['<SOS>']] + [pitch_number_dict['<PAD>']] * 399\n",
    "    target = torch.tensor(target).unsqueeze(0)\n",
    "\n",
    "    # embed the input, [1, 400] -> [1, 400, 32]\n",
    "    x = model.embed(x)\n",
    "\n",
    "    # encoder layer\n",
    "    # x: [1, 400, 32] -> [1, 400, 32]\n",
    "    x = model.encoder(x, mask_pad_x)\n",
    "\n",
    "    # generate the output\n",
    "    # 1 + 8*12 + 7 + 1 = 105\n",
    "    for i in range(105):\n",
    "        y = target\n",
    "\n",
    "        # initialize the mask\n",
    "        mask_tril_y = mask_tril(y)\n",
    "\n",
    "        # embed the output, [1, 400] -> [1, 400, 32]\n",
    "        y = model.embed(y)\n",
    "\n",
    "        # decoder layer\n",
    "        # y: [1, 400, 32] -> [1, 400, 32]\n",
    "        y = model.decoder(x, y, mask_pad_x, mask_tril_y)\n",
    "\n",
    "        # fully connected layer\n",
    "        # y: [1, 400, 32] -> [1, 400, 136]\n",
    "        out = model.fc_out(y)\n",
    "\n",
    "        # get the output for the current position\n",
    "        # out: [1, 400, 136] -> [1, 136]\n",
    "        out = out[:,i,:]\n",
    "\n",
    "        # get the index of the maximum value\n",
    "        # out: [1, 136] -> [1]\n",
    "        out = out.argmax(dim=1).detach()\n",
    "\n",
    "        # update the target\n",
    "        target[:,i+1] = out\n",
    "\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_x(triple_counter):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[129,  74, 135, 135, 135,  69, 135,  67, 135,  66, 135,  64, 135, 133,\n",
      "          62, 135,  79, 135,  78, 135,  76, 135,  78, 135,  76, 135, 133,  74,\n",
      "         135, 135, 135,  69, 135,  67, 135,  66, 135,  64, 135, 133,  62, 135,\n",
      "          74,  73,  74, 135, 135, 135, 135, 135, 135, 135, 133,  78, 135,  76,\n",
      "         135,  74, 135,  76, 135,  78, 135,  74, 135, 133,  79, 135,  78, 135,\n",
      "          76, 135,  78, 135,  79, 135,  76, 135, 133,  78, 135,  76, 135,  74,\n",
      "         135,  81, 135,  79, 135,  78, 135, 133,  76, 135, 135, 135,  69, 135,\n",
      "         135, 135, 135, 135, 135, 135, 133,  78, 135,  76, 135,  74, 135,  73,\n",
      "         135,  71, 135, 135, 135, 133,  79, 135,  78, 135,  76, 135,  74, 135,\n",
      "          73, 135, 135, 135, 133,  74, 135, 135, 135,  69, 135,  67, 135,  66,\n",
      "         135,  64, 135, 133,  62, 135,  74,  73,  74, 135, 135, 135, 135, 135,\n",
      "         135, 135, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "         134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "         134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "         134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "         134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "         134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "         134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "         134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "         134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "         134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "         134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "         134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "         134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "         134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "         134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "         134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "         134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "         134, 134, 134, 134, 134, 134, 134, 130]])\n",
      "tensor([[129, 129, 129, 129,  76,  76,  76,  76,  76,  76,  76,  76,  76,  76,\n",
      "          76,  76,  76,  76,  76,  76,  76,  76,  76,  76,  76,  76,  76,  76,\n",
      "          76,  76,  76,  76,  76,  76,  76,  76,  76,  76,  76,  76,  76,  76,\n",
      "          76,  76,  76,  76,  76,  76,  76,  76,  76,  76,  76,  76,  76,  76,\n",
      "          76,  76,  76,  76,  76,  76,  76,  76,  76,  76,  76,  76,  76,  76,\n",
      "          76,  76,  76,  76,  76,  76,  76,  76,  76,  76,  76,  76,  76,  76,\n",
      "          76,  76,  76,  76,  76,  76,  76,  76,  76,  76,  76,  76,  76,  76,\n",
      "          76,  76,  76,  76,  76,  76,  76,  76, 134, 134, 134, 134, 134, 134,\n",
      "         134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "         134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "         134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "         134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "         134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "         134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "         134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "         134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "         134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "         134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "         134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "         134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "         134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "         134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "         134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "         134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "         134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "         134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "         134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "         134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134,\n",
      "         134, 134, 134, 134, 134, 134, 134, 134]])\n",
      "[129, 135, 135, 135, 69, 135, 67, 135, 66, 135, 64, 135, 133, 62, 135, 79, 135, 78, 135, 76, 135, 78, 135, 76, 135, 133, 74, 135, 135, 135, 69, 135, 67, 135, 66, 135, 64, 135, 133, 62, 135, 74, 73, 74, 135, 135, 135, 135, 135, 135, 135, 133, 78, 135, 76, 135, 74, 135, 76, 135, 78, 135, 74, 135, 133, 79, 135, 78, 135, 76, 135, 78, 135, 79, 135, 76, 135, 133, 78, 135, 76, 135, 74, 135, 81, 135, 79, 135, 78, 135, 133, 76, 135, 135, 135, 69, 135, 135, 135, 135, 135, 135, 135, 133, 78, 135, 76, 135, 74, 135, 73, 135, 71, 135, 135, 135, 133, 79, 135, 78, 135, 76, 135, 74, 135, 73, 135, 135, 135, 133, 74, 135, 135, 135, 69, 135, 67, 135, 66, 135, 64, 135, 133, 62, 135, 74, 73, 74, 135, 135, 135, 135, 135, 135, 135, 133, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 134, 130]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    # x = generate_x(triple_counter)\n",
    "    # pred = predict(x)\n",
    "    # test triple [[(1, 83), (5, 79), (9, 76)]]\n",
    "    # test_triple = [[(1, 83), (5, 79), (9, 76)]]\n",
    "    # test_triple = change_it_to_bar_vectors(test_triple)\n",
    "    # test_x = [pitch_number_dict['<SOS>']] + test_triple[0] + [pitch_number_dict['<PAD>']] * (400-2-len(test_triple[0])) + [pitch_number_dict['<EOS>']]\n",
    "\n",
    "    test_x = x_train[i]\n",
    "\n",
    "    pred = predict(test_x)\n",
    "    print(pred)\n",
    "    print(y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
